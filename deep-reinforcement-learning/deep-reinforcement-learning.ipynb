{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning for Stock Market Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Stock Market Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class stock_trader():\n",
    "    def __init__(self, state_size, action_space=3, model_name='mr_stonks'): # stay, buy, or sell\n",
    "        self.state_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=2000) # no. of elements we can store\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.gamma = 0.95 # discount factor\n",
    "        self.epsilon = 1.0 # probability of random action selection; initialised to random actions\n",
    "        self.epsilon_final = 0.01 # lower bound of epsilon\n",
    "        self.epsilon_decay = 0.995 # rate of decay\n",
    "\n",
    "        self.model = self.model_builder()\n",
    "\n",
    "    def model_builder(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=32, activation='relu', input_dim=self.state_size))\n",
    "        model.add(Dense(units=64, activation='relu'))\n",
    "        model.add(Dense(units=128, activation='relu'))\n",
    "        # Output layer\n",
    "        model.add(Dense(units=self.action_space, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def trade(self, state):\n",
    "        if (random.random() <= self.epsilon): # <= epsilon means a random action is taken; exploration\n",
    "            return random.randrange(self.action_space) # returns a random number between 0-2; stay, buy or sell\n",
    "        \n",
    "        actions = self.model.predict(state)\n",
    "\n",
    "        return np.argmax(actions[0]) # only return action with highest probability\n",
    "\n",
    "    def batch_train(self, batch_size):\n",
    "        batch = []\n",
    "\n",
    "        for i in range(len(self.memory)-batch_size+1, len(self.memory)):\n",
    "            batch.append(self.memory[i])\n",
    "\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            reward = reward\n",
    "            \n",
    "            if (not done): # if not in terminal state (still have actions that can be taken)\n",
    "                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0]) # Deep Q-learning Bellman equation\n",
    "\n",
    "            target = self.model.predict(state)\n",
    "            target[0][action] = reward\n",
    "\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "        # decrease epsilon\n",
    "        if (self.epsilon > self.epsilon_final):\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "# Price format\n",
    "def stocks_price_format(n):\n",
    "    return f'- $ {abs(n):2f}' if (n < 0) else f'$ {abs(n):2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "def dataset_loader(stock_name):\n",
    "  dataset = pdr.DataReader(stock_name, data_source=\"yahoo\")\n",
    "  \n",
    "  start_date = str(dataset.index[0]).split()[0]\n",
    "  end_date = str(dataset.index[-1]).split()[0]\n",
    "  \n",
    "  close = dataset['Close']\n",
    "\n",
    "  return close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State creator\n",
    "def state_creator(data, timestep, window_size):\n",
    "    starting_id = timestep - window_size+1\n",
    "\n",
    "    if (starting_id >= 0):\n",
    "        windowed_data = data[starting_id:timestep+1]\n",
    "    else:\n",
    "        windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
    "\n",
    "    state = []\n",
    "\n",
    "    for i in range(window_size - 1):\n",
    "        state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
    "\n",
    "    return np.array([state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Date\n2015-06-18    127.879997\n2015-06-19    126.599998\n2015-06-22    127.610001\n2015-06-23    127.029999\n2015-06-24    128.110001\n                 ...    \n2020-06-10    352.839996\n2020-06-11    335.899994\n2020-06-12    338.799988\n2020-06-15    342.989990\n2020-06-16    350.480011\nName: Close, Length: 1258, dtype: float64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Stock\n",
    "stock_name = 'AAPL'\n",
    "data = dataset_loader(stock_name)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                352       \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                2112      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               8320      \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 387       \n=================================================================\nTotal params: 11,171\nTrainable params: 11,171\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "window_size = 10\n",
    "episodes = 1000\n",
    "\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1\n",
    "\n",
    "trader = stock_trader(window_size)\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/1257 [00:00<?, ?it/s]Episode: 1/1000\nAI Trader bought:  $ 126.599998\nAI Trader bought:  $ 127.610001\nAI Trader sold:  $ 127.029999  Profit: $ 0.430000\nAI Trader bought:  $ 127.500000\nAI Trader bought:  $ 126.750000\nAI Trader bought:  $ 125.430000\nAI Trader sold:  $ 126.000000  Profit: - $ 1.610001\nAI Trader bought:  $ 125.690002\nAI Trader bought:  $ 122.570000\nAI Trader bought:  $ 125.660004\nAI Trader sold:  $ 125.610001  Profit: - $ 1.889999\nAI Trader bought:  $ 128.509995\nAI Trader bought:  $ 129.619995\nAI Trader sold:  $ 125.220001  Profit: - $ 1.529999\nAI Trader sold:  $ 125.160004  Profit: - $ 0.269997\nAI Trader bought:  $ 122.769997\nAI Trader bought:  $ 123.379997\nAI Trader bought:  $ 122.989998\nAI Trader bought:  $ 122.370003\nAI Trader bought:  $ 118.440002\nAI Trader bought:  $ 114.639999\n  3%|▎         | 33/1257 [00:03<02:14,  9.11it/s]AI Trader bought:  $ 115.400002\n  3%|▎         | 34/1257 [00:06<19:01,  1.07it/s]AI Trader sold:  $ 115.129997  Profit: - $ 10.560005\n  3%|▎         | 35/1257 [00:09<29:54,  1.47s/it]AI Trader sold:  $ 115.519997  Profit: - $ 7.050003\n  3%|▎         | 36/1257 [00:12<38:20,  1.88s/it]AI Trader bought:  $ 119.720001\n  3%|▎         | 38/1257 [00:17<47:42,  2.35s/it]AI Trader bought:  $ 115.239998\n  3%|▎         | 40/1257 [00:23<51:10,  2.52s/it]AI Trader bought:  $ 115.959999\n  3%|▎         | 42/1257 [00:28<53:36,  2.65s/it]AI Trader bought:  $ 116.500000\n  4%|▎         | 44/1257 [00:34<54:21,  2.69s/it]AI Trader bought:  $ 112.650002\n  4%|▎         | 45/1257 [00:36<54:14,  2.69s/it]AI Trader bought:  $ 105.760002\n  4%|▍         | 49/1257 [00:48<58:50,  2.92s/it]AI Trader bought:  $ 112.919998\n  4%|▍         | 50/1257 [00:51<59:53,  2.98s/it]AI Trader bought:  $ 113.290001\n  4%|▍         | 51/1257 [00:54<1:00:04,  2.99s/it]AI Trader bought:  $ 112.760002\n  4%|▍         | 52/1257 [00:57<59:13,  2.95s/it]AI Trader sold:  $ 107.720001  Profit: - $ 17.940002\n  4%|▍         | 53/1257 [01:00<59:55,  2.99s/it]AI Trader sold:  $ 112.339996  Profit: - $ 16.169998\n  4%|▍         | 54/1257 [01:03<59:41,  2.98s/it]AI Trader bought:  $ 110.370003\n  4%|▍         | 55/1257 [01:06<1:00:05,  3.00s/it]AI Trader bought:  $ 109.269997\n  4%|▍         | 56/1257 [01:09<1:00:18,  3.01s/it]AI Trader sold:  $ 112.309998  Profit: - $ 17.309998\n  5%|▍         | 57/1257 [01:12<1:00:03,  3.00s/it]AI Trader sold:  $ 110.150002  Profit: - $ 12.619995\n  5%|▍         | 58/1257 [01:15<59:51,  3.00s/it]AI Trader bought:  $ 112.570000\n  5%|▍         | 60/1257 [01:21<1:00:28,  3.03s/it]AI Trader sold:  $ 115.309998  Profit: - $ 8.070000\n  5%|▍         | 62/1257 [01:27<59:21,  2.98s/it]AI Trader bought:  $ 116.410004\n  5%|▌         | 63/1257 [01:30<59:24,  2.99s/it]AI Trader sold:  $ 113.919998  Profit: - $ 9.070000\n  5%|▌         | 64/1257 [01:33<58:57,  2.97s/it]AI Trader sold:  $ 113.449997  Profit: - $ 8.920006\n  5%|▌         | 66/1257 [01:39<58:37,  2.95s/it]AI Trader bought:  $ 113.400002\n  5%|▌         | 67/1257 [01:42<59:14,  2.99s/it]AI Trader sold:  $ 114.320000  Profit: - $ 4.120003\n  5%|▌         | 68/1257 [01:45<59:36,  3.01s/it]AI Trader bought:  $ 115.000000\n  5%|▌         | 69/1257 [01:48<59:16,  2.99s/it]AI Trader bought:  $ 114.709999\n  6%|▌         | 70/1257 [01:51<1:00:27,  3.06s/it]AI Trader bought:  $ 112.440002\n  6%|▌         | 71/1257 [01:54<1:00:09,  3.04s/it]AI Trader bought:  $ 109.059998\n  6%|▌         | 72/1257 [01:57<1:00:31,  3.06s/it]AI Trader sold:  $ 110.300003  Profit: - $ 4.339996\n  6%|▌         | 72/1257 [02:00<33:01,  1.67s/it]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-796f5e5eac94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mtrader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6c80a08a49bf>\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# if not in terminal state (still have actions that can be taken)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Deep Q-learning Bellman equation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1613\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m     \"\"\"\n\u001b[1;32m-> 1615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m   def interleave(self,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   3966\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3967\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3968\u001b[1;33m         **self._flat_structure)\n\u001b[0m\u001b[0;32m   3969\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mflat_map_dataset\u001b[1;34m(input_dataset, other_arguments, f, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   1728\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FlatMapDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1730\u001b[1;33m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   1731\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(1, episodes+1):\n",
    "    print(f'Episode: {episode}/{episodes}')\n",
    "\n",
    "    # Initialise\n",
    "    state = state_creator(data, 0, window_size+1)\n",
    "    total_profit = 0\n",
    "    trader.inventory = []\n",
    "\n",
    "    for t in tqdm(range(data_samples)):\n",
    "        action = trader.trade(state)\n",
    "        next_state = state_creator(data, t+1, window_size+1)\n",
    "        reward = 0\n",
    "\n",
    "        if (action == 1): # Buying\n",
    "            trader.inventory.append(data[t])\n",
    "            print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "\n",
    "        elif (action == 2) and len(trader.inventory): # Selling\n",
    "            buy_price = trader.inventory.pop(0)\n",
    "\n",
    "            reward = max(data[t]-buy_price, 0)\n",
    "            total_profit += data[t] - buy_price\n",
    "            print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price))\n",
    "\n",
    "        done = True if (t==data_samples-1) else False\n",
    "\n",
    "        trader.memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if (done):\n",
    "            print('########################')\n",
    "            print(f'TOTAL PROFIT: {total_profit}')\n",
    "            print('########################')\n",
    "\n",
    "        if (len(trader.memory) > batch_size):\n",
    "            trader.batch_train(batch_size)\n",
    "\n",
    "    if (episode%10 == 0):\n",
    "        trader.model.save(f'{trader.model_name}-{episode}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupted model training because it will take forever to complete. STONKS"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}